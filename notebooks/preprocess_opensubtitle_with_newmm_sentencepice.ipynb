{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.7\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "import io\n",
    "import random\n",
    "import copy \n",
    "import re\n",
    "import html\n",
    "\n",
    "from time import time \n",
    "from multiprocessing import Pool\n",
    "from collections import Counter\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import pythainlp\n",
    "from pythainlp.util import *\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from pythainlp.ulmfit import *\n",
    "\n",
    "# subword-nmt\n",
    "from subword_nmt import learn_bpe as learner\n",
    "from subword_nmt import apply_bpe as subword_tokenizer\n",
    "\n",
    "import fairseq \n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from pythainlp.tokenize import DEFAULT_DICT_TRIE\n",
    "\n",
    "from pythainlp.corpus import thai_words\n",
    "\n",
    "print(pythainlp.__version__)\n",
    "# assert pythainlp.__version__ == '2.1'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install BPEmb (BPE embeddings)\n",
    "\n",
    "!pip install --q bpemb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bpemb import BPEmb\n",
    "\n",
    "bpemb_pretrained ={\n",
    "    'th': {\n",
    "        '25000': BPEmb(lang=\"th\", vs=25000)\n",
    "    },\n",
    "    'en': {\n",
    "        '25000': BPEmb(lang=\"en\", vs=25000)\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3281534,\n",
       " ['Slave in the Magic Mirror, come from the farthest space.',\n",
       "  'Through wind and darkness, I summon thee.',\n",
       "  'Speak!'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/opensubtitle_v2018/OpenSubtitles.en-th.en','r', encoding='utf-8') as f:\n",
    "    en = f.read().split('\\n')\n",
    "len(en),en[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3281534,\n",
       " ['ทาสในกระจกวิเศษ, มาจากพื้นที่ที่ไกลที่สุด',\n",
       "  'ผ่านลมและความมืดฉันเรียกเจ้า',\n",
       "  'พูด!'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/opensubtitle_v2018/OpenSubtitles.en-th.th','r', encoding='utf-8') as f:\n",
    "    th = f.read().split('\\n')\n",
    "    \n",
    "len(th),th[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseRule:    \n",
    "    def test(self, sentence, lang):\n",
    "        pass\n",
    "\n",
    "class ReplaceRule(BaseRule):   \n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def replace(self, sentence, lang):\n",
    "        pass\n",
    "\n",
    "class UnescapeString(ReplaceRule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        pass\n",
    "        \n",
    "    def test(self, sentence, lang):\n",
    "        return True\n",
    "\n",
    "    def replace(self, sentence, lang):\n",
    "        return unescape_string(sentence)\n",
    "\n",
    "class ReplaceSymbolOccurenceRule(ReplaceRule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_list = ['', '', '​', '', '', '', '",
    "', '', 'โ', '​',\n",
    "                           '♪', '{\\ cHFFFFFF }', '\\cHFFFFFF', '§', 'font color = \"# 808080 \"',\n",
    "                          ' ##', '{\\cHFFFFFF}', '## ', ' ## ', '-# ', '# ', ' #']\n",
    "        \n",
    "    def test(self, sentence, lang):\n",
    "        for token in self.token_list:\n",
    "            if token in sentence:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def replace(self, sentence, lang):\n",
    "        for token in self.token_list:\n",
    "            sentence = sentence.replace(token, '')\n",
    "        return sentence\n",
    "\n",
    "class ReplaceHashtagInSentenceRule(ReplaceRule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        pass\n",
    "        \n",
    "    def test(self, sentence, lang):\n",
    "        if re.match(r\"[[^#]|[^##]]\", sentence):\n",
    "            return True\n",
    "        if re.search(r\"#$\", sentence):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def replace(self, sentence, lang):\n",
    "        sentence = re.sub(r\"^#+\", '', sentence).lstrip()\n",
    "        sentence = re.sub(r\"#$\", '', sentence).rstrip()\n",
    "\n",
    "        return sentence\n",
    "    \n",
    "class ReplaceDashInSentenceRule(ReplaceRule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        pass\n",
    "        \n",
    "    def test(self, sentence, lang):\n",
    "        if ' - ' in sentence:\n",
    "            return True\n",
    "        if '- ' in sentence:\n",
    "            return True\n",
    "        if ' -' in sentence:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def replace(self, sentence, lang):\n",
    "        sentence = re.sub(r\" - \", '', sentence)\n",
    "        sentence = re.sub(r\"- \", '', sentence)\n",
    "        sentence = re.sub(r\" -\", '', sentence)\n",
    "        sentence = re.sub(r\"^[-]+\", '', sentence) # start with space + \"-\" \n",
    "        sentence = re.sub(r\"[-]+$\", '', sentence) # end with space + \"-\" \n",
    "\n",
    "        return sentence\n",
    "    \n",
    "\n",
    "class NormalizeThaiVowel(ReplaceRule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        pass\n",
    "        \n",
    "    def test(self, sentence, lang):\n",
    "        if 'เเ' in sentence and lang == 'th':\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def replace(self, sentence, lang):\n",
    "        sentence = re.sub(r\"เเ\", 'แ', sentence)\n",
    "\n",
    "        return sentence\n",
    "    \n",
    "    \n",
    "class ReplaceDashInSentenceRule(ReplaceRule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        pass\n",
    "        \n",
    "    def test(self, sentence, lang):\n",
    "        if ' - ' in sentence:\n",
    "            return True\n",
    "        if '- ' in sentence:\n",
    "            return True\n",
    "        if ' -' in sentence:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def replace(self, sentence, lang):\n",
    "        sentence = re.sub(r\" - \", '', sentence)\n",
    "        sentence = re.sub(r\"- \", '', sentence)\n",
    "        sentence = re.sub(r\" -\", '', sentence)\n",
    "        sentence = re.sub(r\"^[-]+\", '', sentence) # start with space + \"-\" \n",
    "        sentence = re.sub(r\"[-]+$\", '', sentence) # end with space + \"-\" \n",
    "\n",
    "        return sentence\n",
    "\n",
    "    def replace(self, sentence, lang):\n",
    "        sentence = re.sub(r\" - \", '', sentence)\n",
    "        sentence = re.sub(r\"- \", '', sentence)\n",
    "        sentence = re.sub(r\" -\", '', sentence)\n",
    "        sentence = re.sub(r\"^[-]+\", '', sentence) # start with space + \"-\" \n",
    "        sentence = re.sub(r\"[-]+$\", '', sentence) # end with space + \"-\" \n",
    "\n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "กHello\n",
      "Hello\n",
      "Hello\n",
      "a-sad Hello\n"
     ]
    }
   ],
   "source": [
    "def testReplaceDashInSentenceRule():\n",
    "    rule = ReplaceDashInSentenceRule()\n",
    "    assert rule.test('- ', lang=\"th\") == True\n",
    "    assert rule.test(' -', lang=\"th\") == True\n",
    "    assert rule.test(' - ', lang=\"th\") == True\n",
    "    \n",
    "    print(rule.replace('- Hello', lang=\"th\"))\n",
    "    print(rule.replace(' -กHello', lang=\"th\"))\n",
    "    print(rule.replace('Hello-', lang=\"th\"))\n",
    "    print(rule.replace('---- Hello- ', lang=\"th\"))\n",
    "    print(rule.replace('a-sad Hello--- ', lang=\"th\"))\n",
    "\n",
    "testReplaceDashInSentenceRule()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\n",
      "..\n",
      "..\n",
      "..\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "def testReplaceHashtagInSentenceRule():\n",
    "    rule = ReplaceHashtagInSentenceRule()\n",
    "    assert rule.test('#..', lang=\"th\") == True\n",
    "    assert rule.test('##..', lang=\"th\") == True\n",
    "    assert rule.test('.#', lang=\"th\") == True\n",
    "\n",
    "    print(rule.replace('#..', lang=\"th\"))\n",
    "    print(rule.replace('##..', lang=\"th\"))\n",
    "    print(rule.replace('#### ..', lang=\"th\"))\n",
    "    print(rule.replace('..', lang=\"th\"))\n",
    "    print(rule.replace('.#', lang=\"th\"))\n",
    "\n",
    "testReplaceHashtagInSentenceRule()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "แรกเกิด\n"
     ]
    }
   ],
   "source": [
    "def testNormalizeThaiVowel():\n",
    "    rule = NormalizeThaiVowel()\n",
    "    assert rule.test('เเ', lang='th') == True\n",
    "    \n",
    "    print(rule.replace('เเรกเกิด', lang='th'))\n",
    "testNormalizeThaiVowel()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ContainsAdSymbol(BaseRule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        pass\n",
    "        \n",
    "    def test(self, sentence, lang):\n",
    "        if '@' in sentence:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "class NoThaiWordInThaiSentence(BaseRule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        pass\n",
    "        \n",
    "    def test(self, sentence, lang):\n",
    "        if lang == \"th\":\n",
    "            if countthai(sentence, ignore_chars='') == 0.0:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    \n",
    "class ContainsUnknownSumbols(BaseRule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.list_unknown_symbols = [b'\\x98\\xc2', b'\\xae\\xc2', b'\\x99\\xc2',\n",
    "                                     b'\\xb1\\xc2' , b'\\xc2\\xb7', b'\\xc3\\x83']\n",
    "        \n",
    "    def test(self, sentence, lang):\n",
    "        for symbol in self.list_unknown_symbols:\n",
    "            if symbol in sentence:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "class SentenceLengthLessThanOne(BaseRule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        pass\n",
    "        \n",
    "    def test(self, sentence, lang):\n",
    "        if len(sentence) <= 1:\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def testContainsAdSymbol():\n",
    "    rule = ContainsAdSymbol()\n",
    "    print(rule.test('@gmail', lang=\"th\"))\n",
    "    print(rule.test('gmasd', lang=\"th\"))\n",
    "testContainsAdSymbol()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_REPLACE_RULES = [ReplaceSymbolOccurenceRule,\n",
    "                         ReplaceDashInSentenceRule,\n",
    "                         ReplaceHashtagInSentenceRule,\n",
    "                         UnescapeString,\n",
    "                         NormalizeThaiVowel]\n",
    "\n",
    "DEFAULT_FILTER_OUT_RULES = [ContainsUnknownSymbols,\n",
    "                            ContainsAdSymbol,\n",
    "                            NoThaiWordInThaiSentence,\n",
    "                            SentenceLengthLessThanOne]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess text\n",
    "\n",
    "# LIST_OF_TOKENS_TO_REPLACE = ['', '', '​', '', '', '', '",
    "', '', 'โ', '​',\n",
    "#                    '♪', '{\\ cHFFFFFF }', '§', 'font color = \"# 808080 \"']\n",
    "def unescape_string(text):\n",
    "    return html.unescape(text)\n",
    "\n",
    "def sentences_filter(sentences, lang, rules=DEFAULT_FILTER_OUT_RULES):\n",
    "    indices = []\n",
    "    for index, sentence in tqdm_notebook(enumerate(sentences), total=len(sentences)):\n",
    "        \n",
    "        for rule in rules:\n",
    "            rule_obj = rule()\n",
    "            if rule_obj.test(sentence, lang=lang):\n",
    "                indices.append(index)\n",
    "    return indices\n",
    "\n",
    "def clean_sentence(sentence, lang, rules=DEFAULT_REPLACE_RULES):\n",
    "    for rule in rules:\n",
    "        \n",
    "        rule_obj = rule()\n",
    "        if rule_obj.test(sentence, lang=lang):\n",
    "            sentence = rule_obj.replace(sentence, lang=lang)\n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenize_worker(sentence, lang, trie):\n",
    "    \n",
    "    _tokenizer_newmm = partial(pythainlp.tokenize.word_tokenize, engine='newmm',\n",
    "                               keep_whitespace=False,\n",
    "                              custom_dict=(trie if trie != None else DEFAULT_DICT_TRIE))\n",
    "    return ' '.join(_tokenizer_newmm(sentence))\n",
    "  \n",
    "def tokenize_handler(sentences, lang, trie=None):\n",
    "    toks = []\n",
    "    p = Pool(12)\n",
    "    t = time()\n",
    "    _tokenize_worker = partial(tokenize_worker, lang=lang, trie=trie)\n",
    "    toks = p.map(_tokenize_worker, sentences)\n",
    "    \n",
    "    p.close()\n",
    "    p.join() # call Pool.join() to wait for the worker processes to terminate.\n",
    "\n",
    "    print('{} s'.format(time() -t))\n",
    "\n",
    "    return toks\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_spaced_tokens_to_file(data, folder_name, filename):\n",
    "    with open('/root/mt-opus/data/{}/{}'.format(folder_name, filename),'w') as f:\n",
    "        for item in data:\n",
    "            f.write(item + '\\n')\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence filtering (th)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18cc03d8303412fadcd9705632034ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3281534), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = time()\n",
    "print('sentence filtering (th)')\n",
    "indices_to_filter_out_th = sentences_filter(th, lang='th')\n",
    "\n",
    "print('sentence filtering (en)')\n",
    "indices_to_filter_out_en = sentences_filter(en, lang='en')\n",
    "\n",
    "print(len(indices_to_filter_out_th))\n",
    "print(len(indices_to_filter_out_en))\n",
    "\n",
    "indices_to_filter_out = indices_to_filter_out_th + indices_to_filter_out_en\n",
    "indices_to_filter_out = set(indices_to_filter_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "76544\n",
    "4392"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Sentence\n",
    "\n",
    "print('clean sentence (th)')\n",
    "filtered_th = [clean_sentence(x, lang='th') for i, x in tqdm_notebook(enumerate(th), total=len(th)) if i not in indices_to_filter_out]\n",
    "print('clean sentence (en)')\n",
    "filtered_en = [clean_sentence(x, lang='en') for i, x in tqdm_notebook(enumerate(en), total=len(en)) if i not in indices_to_filter_out]\n",
    "\n",
    "print('{} seconds'.format(time() -t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ทาสในกระจกวิเศษ, มาจากพื้นที่ที่ไกลที่สุด'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_th[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is it? \n",
      " -กับใคร\n",
      "Delighted. \n",
      " -ยินดียิ่ง\n",
      "Wait. \n",
      " -เดี๋ยว\n",
      "Have you any English mustard? \n",
      " -คุณมีมัสตาร์ดอังกฤษไหม\n",
      "Precisely. I sign after. \n",
      " -ได้ หลังจากที่ผมเซ็นสัญญา\n",
      "Why should I? \n",
      " -เรื่องของผม\n",
      "Don't answer back! \n",
      " -ไม่มีคำตอบ\n",
      "Looking this way. \n",
      " -ทำอย่างไรดี\n",
      "Keep going! \n",
      " -เดินต่อไป\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'th found - at the start of sentence': 44687})"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = Counter()\n",
    "\n",
    "for idx, sent in enumerate(filtered_th):\n",
    "    \n",
    "    if re.search('^-',sent):\n",
    "        counter['th found - at the start of sentence'] += 1\n",
    "        if counter['th found - at the start of sentence'] < 10:\n",
    "            print(filtered_en[idx],'\\n', sent)\n",
    "    if '♪' in sent:\n",
    "        counter['th found โช โช'] += 1\n",
    "        if counter['th found โช โช'] < 10:\n",
    "            print(filtered_en[idx],'\\n', sent)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter()"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = Counter()\n",
    "\n",
    "for idx, sent in enumerate(filtered_en):\n",
    "    \n",
    "#     if '-' in sent:\n",
    "#         counter['en found - at the start of sentence'] += 1\n",
    "#         if counter['en found - at the start of sentence'] < 10:\n",
    "#             print(filtered_th[idx],'\\n', sent)\n",
    "#             print()\n",
    " \n",
    "    if len(sent.split('- ')) == 2:\n",
    "        counter['duplicate']  += 1\n",
    "        if counter['duplicate'] < 300:\n",
    "            print(filtered_th[idx])\n",
    "            print(sent)\n",
    "            print()\n",
    " \n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter()"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = Counter()\n",
    "\n",
    "for idx, sent in enumerate(filtered_th):\n",
    "    \n",
    "    if '\\cHFFFFFF' in sent:\n",
    "        counter['th found 0000;'] += 1\n",
    "        if counter['th found 0000;'] < 10:\n",
    "            print(filtered_en[idx])\n",
    "            print(sent)\n",
    "            print()\n",
    " \n",
    " \n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter()"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = Counter()\n",
    "\n",
    "for idx, sent in enumerate(filtered_th):\n",
    "    \n",
    "    if '\\fn' in sent:\n",
    "        counter['th found \\fn'] += 1\n",
    "        if counter['th found \\fn'] < 40:\n",
    "            print(filtered_en[idx])\n",
    "            print(sent)\n",
    "            print()\n",
    " \n",
    " \n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last night, I dreamt I went to Manderley again.\n",
      "เมื่อคืนฉันฝันว่า ได้กลับไปที่เเมนเดอเลย์อีกครั้ง\n",
      "\n",
      "The drive wound away in front of me, twisting and turning as it had always done.\n",
      "ถนนเลื้อยคดเคี้ยวอยู่เบื้องหน้าของฉัน ยังคงคดโค้งเเละวกวนดั่งเช่นเคย\n",
      "\n",
      "Nature had come into her own again, and little by little had encroached upon the drive with long, tenacious fingers.\n",
      "ธรรมชาติได้กลับคืนสู่ตนเองอีกครั้ง ค่อยๆ ปกคลุมทางเข้าทีละน้อย ดั่งนิ้วมืออันเรียวยาวและเหนียวเเน่น\n",
      "\n",
      "On and on wound the poor thread that had once been our drive, and finally, there was Manderley.\n",
      "แผ่ปกคลุมทางเข้าอันซอมซ่อ ที่ครั้งหนึ่งเคยเป็นทางเดินรถของเรา ในที่สุดก็ถึงเเมนเดอเลย์\n",
      "\n",
      "Manderley, secretive and silent.\n",
      "เเมนเดอเลย์-ลึกลับเเละเงียบงัน\n",
      "\n",
      "Time could not mar the perfect symmetry of those walls.\n",
      "กาลเวลามิอาจทําให้กําเเพง ที่ได้สมมาตรนี้ด่างพร้อยได้\n",
      "\n",
      "Moonlight can play odd tricks upon the fancy, and suddenly it seemed to me that light came from the windows.\n",
      "เเสงจันทร์อาจทําให้เกิดภาพลวงตา ทําให้ฉันเห็นว่ามีเเสงไฟ ลอดออกมาจากหน้าต่าง\n",
      "\n",
      "The illusion went with it.\n",
      "เเล้วภาพลวงตาก็มลายหายไป\n",
      "\n",
      "I looked upon a desolate shell with no whisper of the past about its staring walls.\n",
      "ฉันมองขึ้นไปยังโครงตึกอันรกร้าง ไร้ซึ่งเสียงกระซิบจากอดีต ขับขานถึงกําเเพงที่น่าขนลุกนั่น\n",
      "\n",
      "We can never go back to Manderley again. That much is certain.\n",
      "เราไม่มีวันได้กลับไปที่เเมนเดอเลย์อีกเเน่ ไม่มีวัน\n",
      "\n",
      "But sometimes in my dreams, I do go back to the strange days of my life which began for me in the South of France.\n",
      "เเต่บางครั้งในความฝันของฉัน... ฉันได้ย้อนกลับไป ถึงช่วงเวลาที่เเปลกประหลาดในชีวิตของฉัน...\n",
      "\n",
      "Why, it's Max de Winter.\n",
      "นั่น เเม็กซ์ เดอ วินเทอร์นี่นา\n",
      "\n",
      "I'm Edythe Van Hopper.\n",
      "ฉันอีดิธ เเวน ฮอปเปอร์ค่ะ\n",
      "\n",
      "But do sit down and have some coffee.\n",
      "เชิญนั่งดื่มกาเเฟกันก่อนสิคะ\n",
      "\n",
      "Garcon. Coffee, please.\n",
      "บริกร ขอกาเเฟหน่อยครับ\n",
      "\n",
      "Perhaps you don't remember an old woman like me.\n",
      "คุณคงจําสาวเเก่อย่างฉันไม่ได้ละกระมัง\n",
      "\n",
      "No. I'm afraid that sort of thing ceased to amuse me years ago.\n",
      "ไม่ครับ ผมหมดสนุกกับการเล่นพนันมานานเเล้ว\n",
      "\n",
      "I can well understand that. As for me, if I had a home like Manderley,\n",
      "เรื่องนี้ฉันพอเข้าใจค่ะ เพราะถ้าฉันมีบ้านเหมือนเเมนเดอเลย์ละก็\n",
      "\n",
      "I should certainly never come to Monte.\n",
      "ฉันก็คงไม่มาที่มอนติ คาร์โลเเน่\n",
      "\n",
      "Now that we've found each other again, I hope I shall see something of you.\n",
      "ไหนๆ เราก็ได้เจอกันเเล้ว ฉันหวังว่าจะได้พบคุณอีก\n",
      "\n",
      "You must come and have a drink in my suite.\n",
      "เเวะมาดื่มกันที่ห้องสวีทของฉันสิคะ\n",
      "\n",
      "Your valet has unpacked for you, I suppose?\n",
      "ฉันว่าเด็กรับใช้ของคุณคงยังไม่ได้ เเกะสัมภาระให้คุณเลยสิท่า\n",
      "\n",
      "Well, I...\n",
      "เเหม--\n",
      "\n",
      "Perhaps you could make yourself useful to Mr. De Winter if he wants anything done.\n",
      "ฉันว่าเธอควรทําตัวให้เป็นประโยชน์ เเล้วไปช่วยคุณเดอ วินเทอร์ดีกว่า\n",
      "\n",
      "Have you got the key?\n",
      "มีกุญเเจรึเปล่า\n",
      "\n",
      "Yes, Mrs. Van Hopper.\n",
      "มีค่ะ คุณนายเเวน ฮอปเปอร์\n",
      "\n",
      "I suppose he was in love with me and wasn't quite sure of himself.\n",
      "ฉันคิดว่าเขาคงเเอบหลงรักฉัน เเต่อายไม่กล้าสู้หน้า\n",
      "\n",
      "By the way, my dear, don't think that I mean to be unkind, but you were just a teeny-weeny bit forward with Mr. De Winter.\n",
      "อ้อ อย่าหาว่าฉันไม่มีเมตตา เเต่ที่เธอเสนอหน้าไปนิดกับคุณเดอ วินเทอร์\n",
      "\n",
      "Your effort to enter the conversation quite embarrassed me, and I'm sure it did him.\n",
      "พยายามเข้ามาเเทรกบทสนทนาน่ะ ทําให้ฉันขายหน้า ฉันว่าเขาก็รู้สึกเช่นกัน\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'th found ? ': 11467})"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = Counter()\n",
    "\n",
    "for idx, sent in enumerate(filtered_th):\n",
    "    \n",
    "    if re.search(\"เเ\", sent):\n",
    "        counter['th found ? '] += 1\n",
    "        if counter['th found ? '] < 30:\n",
    "            print(filtered_en[idx])\n",
    "            print(sent)\n",
    "            print()\n",
    " \n",
    " \n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_counter = {\n",
    "    'th': Counter(),\n",
    "    'en': Counter()\n",
    "}\n",
    "for i in range(len(filtered_th)):\n",
    "    for lang in ['th', 'en']:\n",
    "        if lang == 'th':\n",
    "            sentence_counter[lang][filtered_th[i]] += 1\n",
    "        if lang == 'en':\n",
    "            sentence_counter[lang][filtered_en[i]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ใช่', 10060),\n",
       " ('โอเค', 6404),\n",
       " ('ไม่', 6391),\n",
       " ('ขอบคุณ', 4641),\n",
       " ('เฮ้', 3253),\n",
       " ('อะไรนะ?', 3093),\n",
       " ('ครับ', 2550),\n",
       " ('อะไรนะ', 2524),\n",
       " ('อะไร?', 2503),\n",
       " ('ไม่!', 2033)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_counter['th'].most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('What?', 13096),\n",
       " ('Yeah.', 12215),\n",
       " ('No.', 10685),\n",
       " ('Okay.', 7960),\n",
       " ('Yes.', 6557),\n",
       " ('Thank you.', 6445),\n",
       " ('Hey.', 4256),\n",
       " ('No!', 3748),\n",
       " (\"I don't know.\", 3616),\n",
       " ('Why?', 3542)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_counter['en'].most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "โซ | Zoe\n",
      "โซ | Zo?\n",
      "โซ | Zo?\n",
      "โซ | Zo?\n",
      "โซ | Zo?\n"
     ]
    }
   ],
   "source": [
    "print_only = 100\n",
    "count = 0\n",
    "for i in range(len(filtered_th)):\n",
    "    if filtered_th[i] == 'โซ' and count < print_only:\n",
    "        print(filtered_th[i], '|', filtered_en[i])\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "บางคนก็เรียกเขาว่าผอมโซ ฉัน ทำ. | He was a tall chap. Some would call him weedy.\n",
      "เจ้าพ่อฉันมีลูกสาวคนหนึ่ง ที่คุณเห็นเธอและเอ็นโซ ... | Godfather, I have a daughter. You see, she and Enzo...\n",
      "นั้นเป็นที่พวกเขามี พิแคโซ นั้น ใช่ | That's where they got that Picasso.Yep.\n",
      "เช้าวันนี้มีการเฝ้าระวังอเมริกัน ดาวเทียมถูกตีด้วยเลเซอร์โซ เวียต ไล่ออกจากสถานีอวกาศ เสอจี คิรอฟ | This morning an American surveillance satellite was struck by a Soviet laser fired from the Sergei Kirov Space Station.\n",
      "คุณพระจิโซ ขอหลบฝนที่นี่นะคะ | Dear Guardian Spirit Let us stay until the rain stops\n",
      "นายแบลร์เราจะซื้อปิกัสโซ OK? | Mr Blair, we are buying a Picasso. OK?\n",
      "ฉันสั่ง ออสโซ บูโก้. | I ordered the osso buco.\n",
      "นี่ ออสโซ บูโก้ของนาย. | Here's your osso buco.\n",
      "โอ้ จุง โซ รอลุงแปปนึงนะ เด่งลุงกลับมาพร้อมเงินเยอะๆเลย | Because we're looking for the truth.\n",
      "โซ ไปโรงเรียนเองนะ แล้วก้อจุง..คุณนักสืบ ฝากด้วยนะ | How not all of them own apartment complexes.\n",
      "ดอนน่า จูเลียวัย 23 และแต่งงานแล้ว เป็นภรรยาที่ซื่อสัตย์และทุ่มเท ให้กับ ดอนอัลฟองโซ ชายวัย 50 | Dona Julia was 23 and married, the faithful and devoted wife of Don Alfonso... a man of 50.\n",
      "เพราะว่า ดอนอัลฟองโซ จากไปเสียนาน เพื่อทำธุรกิจค้าขาย และทำให้ผมสามารถอยู่ในบ้านดอนน่า จูเลีย | As for Don Alfonso... he spent so much time away handling the details of his trading business, that I was practically able to live in Dona Julia's house.\n",
      "ผมจำเป็นต้องรู้เกี่ยวกับดอนอัลฟองโซ เกี่ยวกับพ่อของเขา ดอนอันโตนิโย | I need to know about Don Alfonso, about his father, Don Antonio,\n",
      "อึนโซ น่าสงสารจัง | Poor Eun-suh...\n",
      "จุนโซ นายทำอะไรเพื่อเธอมั่งไหม? | Joon-suh, what did you do for her?\n",
      "อึนโซ ค้างที่นี้นะ | Eun-suh, sleep over tonight.\n",
      "แม่ป่วยเพราะคิดถึงอึนโซ พ่อกับพี่เองก็ลำบากใจที่ต้องใช้ชีวิตอยู่กับฉัน | Mom was sick from missing Eun-suh, and you and Dad felt uncomfortable with me...\n",
      "อึนโซ ... | Eun-suh...\n",
      "อึนโซ พี่ไม่เป็นไรนะ | Eun-suh, it's all right with me.\n",
      "จำ ยุน จุนโซ ไม่ได้รึ ? | Don't you know Yoon Joon-suh?\n",
      "อึนโซ ฉันกลัว | Eun-suh, I'm afraid.\n",
      "เค้าไม่ใช่ ยุน อึนโซ คนเดิมอีกแล้ว | I'm not the old Eun-suh anymore.\n",
      "อึนโซ เห็นอะไรดีในตัวเธอนะ | I don't know why you're so popular with women.\n",
      "จุนโซ คงวาดรูปเธอออกบ่อยนะ? | Has Joon-suh painted you a lot?\n",
      "คุณตัดสินใจย้ายมา ซคโซ และใช้ชีวิตอยู่กับอึนโซตามลำพัง | You decided to move to Sokcho, and live with Eun-suh all by yourself.\n",
      "ฉันรู้ว่าฉันคงให้อะไรไม่ได้มากกับจุนโซ และมีหลายครั้งที่ฉันควรปล่อยเขาไป | I know I can't do much for Joon-suh, and I thought of leaving him many times.\n",
      "ถ้าเธอยังอยู่กับพี่จุนโซ สักวันเธอคงได้พบกับแม่อีกครั้ง ฉันกลัวแม่จะยิ่งอาการหนักอีก | If you live with Joon-suh, you'll eventually meet Mom again and I'm afraid she'll get sick again.\n",
      "ในเมืองพาสโซ ฟุนโด ประเทศบราซิล ถูกส่งไปที่สำนักข่าวท้องถิ่น และเราได้รับภาพทางดาวเทียมเมื่อไม่กี่นาทีที่ผ่านมา | It was sent to the local news bureau there and sent to us via satellite just a few minutes ago.\n",
      "สวัสดีครับ ผม โซ ดองกิ นะ คุณอยากออกไปข้างนอกไหม? | Hi, this is Seo Dong-ki Would you like to go out?\n",
      "โซ ดอง กิ | Seo Dong-ki\n",
      "ผมคิดว่า ดินอซโซ พูดถูก | What do you think happened, Duck?\n",
      "10 นาทีเท่านั้น เลียวนาร์ด ท่านทำเต็มที่แล้ว เจ้าหน้าที่ดินอซโซ NCIS มีอะไรบ้าง | Gibbs... everyone on board has been vetted by us for years except you.\n",
      "ดินอซโซ มัวนั่งบื้อทำอะไรอยู่ จัดทีมไปตรวจร้านซักรีดของพวกนั้น | Yeah, I found traces of DMSO in the collars and the cuffs.\n",
      "กัปตัน คาลิโซ โรเจอร์ | Captain Kaliso, come on.Roger.\n",
      "ฮัทโตริ คันโซ มาแล้ว! | Kanzo Hattori has arrived!\n",
      "นินจาอิกะ , คันโซ ฮัตโตริ , มาที่นี่แล้ว | Iga Ninja, Kanzo Hattori, at your service.\n",
      "นินจาอิกะ , คันโซ ฮัตโตริ ผมมาแล้ว | Iga Ninja, Kanzo Hattori has arrived!\n",
      "คันโซ ฮัตโตริ กลับมาแล้ว นิน! | Kanzo Hattori has returned!\n",
      "ครั้งหนึ่งใน เอล ปาโซ ผมมีถุงใบหนึ่ง | Once in El Paso, I had this bag of...\n",
      "เหมือนพวกไฮโซ แต่ไม่ค่อยมีกะตังค์อะนะ | Kinda like a cat lady, but without any cats.\n",
      "ฮัน โซ ยัง | HANG Seo-young\n",
      "ฉลากของมันถูกออกแบบโดย เอ็นโซ ฟรานเชสโก้ ศิลปินอวองการ์ทที่มีชื่อเสียง | Its label is designed by Enzo Francesco a famous avant garde artist.\n",
      "ฉลากของมันถูกออกแบบโดย เอ็นโซ ฟรานเชสโก้ ศิลปินอวองการ์ทที่มีชื่อเสียง | Its label is designed by Enzo Francesco a famous avant garde artist.\n",
      "ดีใจกับ ซาวาโนะ เก็นโซ ที่จะออกเดินทาง ไปร่วมกองทัพ บันไซ! | Congratulations to Sawano Genzo's departure into the army! BANZAI!\n",
      "ขอบคุณมาก ผม ซาวาโนะ เก็นโซ จะไปรบ! | Thank you very much. I, Sawano Genzo, will go off to fight!\n",
      "เซตะ ไทโซ อาการไม่ดี | Seita-san, Teizo is not doing well\n",
      "แม่ไม่ยอมให้ ไทโซ ตายไปด้วยหรอก! | I can't let Teizo die too!\n",
      "ไทโซ แม่ดีใจที่ลูกดีขึ้น ทานเยอะๆ นะ | Teizo, I'm glad you're better. Eat up and get nutrition.\n",
      "แม้แต่เด็กเล็กๆ อย่าง ยูกิ กับ ไทโซ ยังไปช่วยฉันกับพวกเจ้าหน้าที่หมู่บ้าน | Even little Yuki and Teizo are helping me with the fields with our tonarigumi\n",
      "แม้ว่าฉันจะมีข้าวมากขึ้น ถึงแม้จะแค่เมล็ดเดียว ฉันจะให้ ไทโซ หรือ นัตซึ | Even if I had more rice, even if it be one grain, I'd give it to Teizo or Natsu\n",
      "เมื่อคนพบว่าตัวเองหิวโซ และปราศจากความช่วยเหลือใดๆทั้งสิ้น | A guy finds himself starving, cut off from supplies or help\n",
      "แปลกมาก... เขาให้ดาบพิเศษกับองค์ชายแดโซ แล้วตอนนี้เขากำลังจะไปเป็นตัวประกันให้เขาอีก | Amazing...he gave the special sword to Prince Dae-So's hands and now he's going as a peace treaty for him?\n",
      "ถึงแม้ว่าข้าจะบอกให้เจ้าโอนอ่อนผ่อนตาม และอย่เผชิญหน้ากับแดโซ แต่การไปฮั่นไม่ใช่เรื่องที่ถูก | Even though I told you to lay low and avoid confrontation with Dae-So, but going to the Hans is not right.\n",
      "ตอนนี้พวกเราคิดว่าน่าจะเป็นองค์ชายแดโซ แต่ตอนนี้เขามีอำนาจมาก มันจะกลายเป็นเอาไข่ไปปาก้อนหิน | For a moment we thought it might be against Prince Dae-So, but he has so much power it would be like hitting a rock with an egg.\n",
      "แดโซ องค์รัชทายาทอยากพบท่าน | Dae-So, His Royal Highness, would like to see you.\n",
      "ยองโพพยายามจะฆ่าแดโซ แต่เขาทำไม่สำเร็จ | Young-Po attempt to kill Prince Dae-So, but he failed.\n",
      "ถึงแม้ตอนนี้องค์ชายจะถูกจำคุกอยู่ ด้วยเรื่องส่วนตัวขององค์ชายแดโซ เขาคงไม่ได้รับอนุญาตให้มีชีวิตอยู่ต่อไป | Although he is only in prison now, because of Prince Dae-So's personality, he might not be allowed to live.\n",
      "ก่อนเจ้าจะไปฉางอัน แต่งงานกับ เย โซ ยา | Before you leave for Chang'an, marry Yesoya.\n",
      "ข้ามีโชคชะตาร่วมกับหัวหน้าเผ่าเครู แม่นางโซ ซอ โน | I shared a fate with the Chief of GyehRu, Miss So Seo-No.\n",
      "แดโซ เจ้า... จะฆ่ายองโพจริงๆ เหรอ? | Dae-So, are you really going to kill Young-Po?\n",
      "หัวหน้าของคเยรูคือ โซ ซอ โน | The chief of GyehRu is So Seo-No.\n",
      "เจ้าได้รับความไว้วางใจจากแดโซ แต่เจ้ายังวางใจไม่ได้ เพราะเจ้ายังมีงานอีกมากที่ต้องทำ | You got Dae-So's trust, but you cannot relax since you still have so much to do.\n",
      "โซ ซอ โน ทางนั้น... | So Seo-No, the way she looked...\n",
      "เพราะเป็นปฏิปักษ์กับพระมเหสีกับองค์ชายแดโซ เจ้าคงถูกลบหลู่อย่างมากเพื่อปกป้องจูมง | Against the Queen and Dae-So, you had so much humiliation to keep Ju-Mong safe.\n",
      "ถึงแม้ว่าพระองค์ยังไม่พระราชทาน อำนาจทางการทหารให้กับเจ้าชายยองโพ ความจริงที่ว่าพระองค์ทรงมอบหมายงานให้เจ้าชายแดโซ ทางการเมืองและการทหาร ของต่างเมืองนั่นหมายถึงอำนาจเต็มที่ และเป็นงานที่สำคัญมาก | Even though he has given military authority to Prince Young-Po, the fact that he has given Prince Dae-So the task of understanding the political and military status of foreign lands is an enormously powerful and important task.\n",
      "นั่นหมายถึงพระองค์ได้เลือก เจ้าชายแดโซ เป็นรัชทายาท | This means that His Majesty has chosen Prince Dae-So as his successor.\n",
      "ข้าแดโซ ข้าได้ยินเรื่องของท่านมาจากเสด็จพ่อ | I am Dae-So. I have heard of you from my father.\n",
      "เมื่อเขาถามถึงสาเหตุอาการบาดเจ็บขององค์ชายแดโซ ข้าจะทูลฝ่าบาทว่ายังไง? | When he asks for the cause of Dae-So's injury, what should I tell him? !\n",
      "และ ฮักโซ ที่ว่า มัีนไม่ใช่ชื่อคนหรอกค่ะ | And vingt-quatre Haxo, it's not an ID stamp.\n",
      "โซ ฟี! | Sophie!\n",
      "โซ ฟี! | Sophie!\n",
      "โซ ฟี? | Sophie?\n",
      "ของที่คาสิโนในฮ่องกง อยู่ในความดูแลของ ฮวาน โซ เหมียว | The stocks of Hong Kong Casino belong to a man named Hwang So-myeong.\n",
      "นาซิสโซ เพนา โซเรียโน ยินดีรับใช้ | Narciso Pena Soriano, at your service.\n",
      "นาร์ซิโซ โรดริกูเอซนั่นก็ปลื้ม | Okay, Narciso Rodriguez. This we love.\n",
      "นี่เป็นลูกสาวผมปาร์คฮุนโซ ลูกสาวผม... | This is my daughter Park Hyun-seo. My daughter...\n",
      "ฮุนโซ นี่พ่อนะ | Hyun-seo. It's your Dad.\n",
      "ฮุนโซ ฮุนโซ | Hyun-seo! Hyun-seo!\n",
      "ฮุนโซ ที่สะพานวองโฮ ด้านเหนือ ด่วน | Hyun-seo Wonhyo Bridge North Side Hurry!\n",
      "ลูกสาวผม ฮุนโซ เธออยู่ใต้สะพานวองโฮ | My daughter Hyun-seo is under Wonhyo Bridge.\n",
      "ฮุนโซ พ่อขอโทษ... . | Hyun-seo, I'm sorry...\n",
      "ฮุนโซ รู้มั๊ยว่าฉันอยากได้อะไร นมรสกล้วยไง | Hyun-seo, you know what I want? Banana milk.\n",
      "ฮุนโซ นี้พ่อเอง | Hyun-seo! It's Daddy!\n",
      "แต่คุณต้องออกไปจากที่นี้ คุณควรกลับไปขึ้นรถคันยาวๆของคุณ ที่ดูโฮโซ แต่ฉันก็ยังอยู่ที่นี้ | But you're going to leave here, and you're going to take your town car back to your soho loft, and I'm still gonna be here-out of work and dealing with problems that you'll never understand.\n",
      "ฝ่าบาททรงอนุญาตให้แดโซ นำทหารไปงั้นหรือ | Did His Majesty allow Dae-So to lead an army?\n",
      "อัลฟอนโซ คุณยอดมาก | ALFONSO,YOU'RE A STUD.\n",
      "แล้วนี่คือแดน หนุ่มนอกวงไฮโซ ปิ๊งรักในวัยเด็กเขากลับมาแล้ว | And then there's Dan, the outsider. Looks like his childhood crush has returned.\n",
      "ผมรู้เรื่องทุกอย่างเกี่ยวกับคุณ เทเคโซ เคนไซ หือ? | huh?\n",
      "เคนไซ ทาเคโซ ไม่สู้เพื่อเงิน | kenseI takezo does not fight for money.\n",
      "ตั้งแต่เด็กผมอ่านหนังสือ ตำนานของ ทาเคนโซ เคนไซ | as a boy I read the book the trials of takezo kensei.\n",
      "เอสเปรสโซ เติมเหล้านิดหน่อย | Espresso. With a shot of liqueur.\n",
      "เธอก็มันพวกไฮโซ มันน่าจะดีสำหรับเธอมากกว่า | You're like them so it's okay for you\n",
      "บอกอะไรให้ พวกวัวเนื้อของนาย เอาไปเลี้ยงพวกหมาหิวโซ ยังไม่ได้เลย | You know... them beeves of yours, they wouldn't even have fed a hungry dog.\n",
      "เรากำลังไป เอลปาโซ ที่เท็กซัส แล้วรู้มั๊ย มีใครสักกี่คนที่ฉันรู้จักที่นั่น | We're goin' to El Paso Texas. You know how many people I know in El Paso Texas?\n",
      "-คันที่จะไปเอลปาโซ แต่อย่าถามว่าไปทำไมนะ | We're going to El Paso. Don't ask me why.\n",
      "ครูโซ ? | Crusoe?\n",
      "ครูโซ ออกมา | Crusoe, come out.\n",
      "ครูโซ ออกมาเถอะ | Crusoe, please come out.\n",
      "ครูโซ นายไปอยู่ไหน | Crusoe, where the devil are you?\n",
      "ครูโซ ไม่ | Crusoe, no!\n"
     ]
    }
   ],
   "source": [
    "print_only = 100\n",
    "count = 0\n",
    "for i in range(len(filtered_th)):\n",
    "    if 'โซ ' in filtered_th[i] and count < print_only:\n",
    "        print(filtered_th[i], '|', filtered_en[i])\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "toks = {\n",
    "    'th': {\n",
    "        'sentencepiece': [],\n",
    "        'newmm':[]\n",
    "    },\n",
    "    'en': {\n",
    "        'sentencepiece': [],\n",
    "        'newmm':[]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a Segment texts into tokens with `newmm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.81156301498413 s\n",
      "39.77449178695679 s\n"
     ]
    }
   ],
   "source": [
    "toks['th']['newmm'] = tokenize_handler(filtered_th, lang='th')\n",
    "toks['en']['newmm'] = tokenize_handler(filtered_en, lang='en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ทาส ใน กระจก วิเศษ , มาจาก พื้นที่ ที่ ไกล ที่สุด',\n",
       "  'ผ่าน ลม และ ความมืด ฉัน เรียก เจ้า',\n",
       "  'พูด !',\n",
       "  'ให้ ฉัน เห็น พระพักตร์ ของ พระองค์',\n",
       "  'สิ่ง ที่ เจ้า จะ รู้ ว่า สมเด็จ พระราชินี ของ ฉัน ได้ อย่างไร',\n",
       "  'กระจก วิเศษ บน ผนัง ผู้ ที่ เป็น สังขาร หนึ่ง ทั้งหมด หรือไม่',\n",
       "  'ที่ มีชื่อเสียง เป็น ความงาม ของ เจ้า พระ บาท สมเด็จ พระเจ้าอยู่หัว',\n",
       "  'แต่ ถือเป็น แม่บ้าน ที่ น่ารัก ที่ ฉัน เห็น',\n",
       "  'ยาจก ไม่ สามารถ ซ่อน พระคุณ อ่อนโยน ของ เธอ',\n",
       "  'อนิจจา เธอ มี ความเป็นธรรม มากขึ้น กว่า เจ้า'],\n",
       " ['Slave in the Magic Mirror , come from the farthest space .',\n",
       "  'Through wind and darkness , I summon thee .',\n",
       "  'Speak !',\n",
       "  'Let me see thy face .',\n",
       "  'What wouldst thou know , my Queen ?',\n",
       "  'Magic Mirror on the wall , who is the fairest one of all ?',\n",
       "  'Famed is thy beauty , Majesty .',\n",
       "  'But hold , a lovely maid I see .',\n",
       "  'Rags cannot hide her gentle grace .',\n",
       "  'Alas , she is more fair than thee .'])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks['th']['newmm'][0:10], toks['en']['newmm'][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b Segment texts into BPE tokens with SentencePiece (BPEmb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_bpe(sentences, lang, n_vocab=25000):\n",
    "    \"\"\"Return a list of bpe tokens give a list of sentences\"\"\"\n",
    "    segmented_sentences = []\n",
    "    for sentence in tqdm_notebook(sentences, total=len(sentences)):\n",
    "#         print(sentence)\n",
    "        bpe_tokens = bpemb_pretrained[lang]['{}'.format(n_vocab)].encode(sentence)\n",
    "        segmented_sentences.append(' '.join(bpe_tokens))\n",
    "        \n",
    "    return segmented_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Thai language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce4eb5e8cbe469886307235a01f1dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3202751), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['▁ท าส ใน กระจก วิเศษ , ▁มาจาก พื้นที่ ที่ ไกล ที่สุด', '▁ผ่าน ลม และความ มืด ฉัน เรียก เจ้า', '▁พูด !', '▁ให้ ฉัน เห็น พระพักตร์ ของ ▁พระองค์', '▁สิ่งที่ เจ้า จะ รู้ว่า สมเด็จพระราชินี ▁ของ ฉัน ได้อย่างไร', '▁กระจ ก วิเศษ บน ผนัง ▁ผู้ ที่เป็น สัง ขาร หนึ่ง ทั้งหมด ▁หรือไม่', '▁ที่มีชื่อเสียง เป็น ความงาม ของ ▁เจ้า พระบาทสมเด็จพระ เจ้าอยู่หัว', '▁แต่ ถือเป็น แม่ บ้าน ที่น ่ารัก ที่ ฉัน ▁เห็น', '▁ยา จก ไม่สามารถ ซ่อน พระคุณ ▁อ่อน โยน ของเธอ', '▁อน ิจ จา เธอ มีความเป็น ธรรม ▁มาก ขึ้น กว่า เจ้า']\n"
     ]
    }
   ],
   "source": [
    "toks['th']['sentencepiece'] = encode_bpe(filtered_th, 'th', 25000)\n",
    "\n",
    "print(toks['th']['sentencepiece'][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 English language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0ac2a9e16c4fe0814a82c713b07a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3202751), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['▁slave ▁in ▁the ▁magic ▁mirror , ▁come ▁from ▁the ▁fart hest ▁space .', '▁through ▁wind ▁and ▁darkness , ▁i ▁summon ▁the e .', '▁speak !', '▁let ▁me ▁see ▁thy ▁face .', '▁what ▁would st ▁thou ▁know , ▁my ▁queen ?', '▁magic ▁mirror ▁on ▁the ▁wall , ▁who ▁is ▁the ▁fa ire st ▁one ▁of ▁all ?', '▁famed ▁is ▁thy ▁beauty , ▁majesty .', '▁but ▁hold , ▁a ▁lov ely ▁maid ▁i ▁see .', '▁ra gs ▁cannot ▁hide ▁her ▁gentle ▁grace .', '▁al as , ▁she ▁is ▁more ▁fair ▁than ▁the e .']\n"
     ]
    }
   ],
   "source": [
    "toks['en']['sentencepiece']  = encode_bpe(filtered_en, 'en', 25000)\n",
    "print(toks['en']['sentencepiece'][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split train-valid-test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N =  3202751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2562200, 320275, 320276)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train-valid-test split 80/10/10\n",
    "\n",
    "n = len(toks['th']['newmm'])\n",
    "\n",
    "print('N = ',n)\n",
    "idx = list(range(n))\n",
    "\n",
    "random.seed(1234) # Set SEED\n",
    "random.shuffle(idx)\n",
    "\n",
    "train_idx, valid_idx, test_idx = idx[:int(n*0.8)], idx[int(n*0.8):int(n*0.9)], idx[int(n*0.9):]\n",
    "\n",
    "dataset_split = {}\n",
    "dataset_split['train'] = train_idx\n",
    "dataset_split['valid'] = valid_idx\n",
    "dataset_split['test'] = test_idx\n",
    "\n",
    "\n",
    "len(train_idx),len(valid_idx),len(test_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'train': {\n",
    "        'en': {\n",
    "            'sentencepiece': [],\n",
    "            'newmm':[]\n",
    "        },\n",
    "        'th': {\n",
    "             'sentencepiece': [],\n",
    "            'newmm':[]\n",
    "        }\n",
    "    },\n",
    "    'valid': {\n",
    "        'en': {\n",
    "            'sentencepiece': [],\n",
    "            'newmm':[]\n",
    "        },\n",
    "        'th': {\n",
    "             'sentencepiece': [],\n",
    "            'newmm':[]\n",
    "        }\n",
    "    },\n",
    "    'test': {\n",
    "        'en': {\n",
    "            'sentencepiece': [],\n",
    "            'newmm':[]\n",
    "        },\n",
    "        'th': {\n",
    "             'sentencepiece': [],\n",
    "            'newmm':[]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "for split_name in ['train', 'valid', 'test']:\n",
    "    for lang in ['th', 'en']:\n",
    "        for tok_type in ['sentencepiece', 'newmm']:\n",
    "\n",
    "            dataset[split_name][lang][tok_type] = [toks[lang][tok_type][i] for i in dataset_split[split_name]] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['เบค กี้ เธอ ทำท่า แปลก ๆ เมื่อกี้ ใน ห้อง', 'อยู่ กับ เธอ แอน นา จะ นำทาง คุณ ผม จะ กลับ ไป'] \n",
      "\n",
      "['Becky , um , you were acting particularly strange in there just now .', \"Stay with her so Anna can guide you . I ' m going back .\"] \n",
      "\n",
      "['▁เบ ค กี้ ▁เธอ ทํา ท่า แปลก ๆ ▁เมื่อ กี้ ▁ในห้อง', '▁ อยู่กับ เธอ ▁แอนนา จะนํา ทาง คุณ ▁ผม จะ กลับไป'] \n",
      "\n",
      "['▁bec ky , ▁um , ▁you ▁were ▁acting ▁particularly ▁strange ▁in ▁there ▁just ▁now .', \"▁stay ▁with ▁her ▁so ▁anna ▁can ▁guide ▁you . ▁i ' m ▁going ▁back .\"] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train']['th']['newmm'][0:2],'\\n')\n",
    "print(dataset['train']['en']['newmm'][0:2],'\\n')\n",
    "print(dataset['train']['th']['sentencepiece'][0:2],'\\n')\n",
    "print(dataset['train']['en']['sentencepiece'][0:2],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'en_train_n_toks': 92383739, 'th_train_n_toks': 86683223, 'en_valid_n_toks': 11536351, 'en_test_n_toks': 11535798, 'th_test_n_toks': 10833242, 'th_valid_n_toks': 10826042})\n"
     ]
    }
   ],
   "source": [
    "# Counting number of tokens for train, valid, test\n",
    "counter = Counter( )\n",
    "for dataset_type in ['train', 'valid', 'test']:\n",
    "    for th_sent_toks in dataset[dataset_type]['th']['newmm']:\n",
    "        counter['th_{}_n_toks'.format(dataset_type)] += len(th_sent_toks)\n",
    "    for en_sent_toks in dataset[dataset_type]['en']['newmm']:\n",
    "        counter['en_{}_n_toks'.format(dataset_type)] += len(en_sent_toks)\n",
    "\n",
    "print(counter) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create directories: \n",
      "dir: ../data/opensubtitles_tok/sentencepiece-sentencepiece/th-en\n",
      "dir: ../data/opensubtitles_bin/sentencepiece-sentencepiece/th-en\n",
      "create directories: \n",
      "dir: ../data/opensubtitles_tok/sentencepiece-sentencepiece/en-th\n",
      "dir: ../data/opensubtitles_bin/sentencepiece-sentencepiece/en-th\n",
      "create directories: \n",
      "dir: ../data/opensubtitles_tok/sentencepiece-newmm/th-en\n",
      "dir: ../data/opensubtitles_bin/sentencepiece-newmm/th-en\n",
      "create directories: \n",
      "dir: ../data/opensubtitles_tok/sentencepiece-newmm/en-th\n",
      "dir: ../data/opensubtitles_bin/sentencepiece-newmm/en-th\n",
      "create directories: \n",
      "dir: ../data/opensubtitles_tok/newmm-sentencepiece/th-en\n",
      "dir: ../data/opensubtitles_bin/newmm-sentencepiece/th-en\n",
      "create directories: \n",
      "dir: ../data/opensubtitles_tok/newmm-sentencepiece/en-th\n",
      "dir: ../data/opensubtitles_bin/newmm-sentencepiece/en-th\n",
      "create directories: \n",
      "dir: ../data/opensubtitles_tok/newmm-newmm/th-en\n",
      "dir: ../data/opensubtitles_bin/newmm-newmm/th-en\n",
      "create directories: \n",
      "dir: ../data/opensubtitles_tok/newmm-newmm/en-th\n",
      "dir: ../data/opensubtitles_bin/newmm-newmm/en-th\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for tok_type_src in ['sentencepiece', 'newmm']:\n",
    "    for tok_type_tgt in ['sentencepiece', 'newmm']:\n",
    "        langs = ['th', 'en']\n",
    "        for lang in langs:\n",
    "            src_lang = lang\n",
    "            tgt_lang = 'en' if lang =='th' else 'th'\n",
    "            FOLDER_NAME = \"opensubtitles_tok/{}-{}/{}-{}\".format(tok_type_src, tok_type_tgt, src_lang, tgt_lang )\n",
    "            FOLDER_NAME_BIN = \"opensubtitles_bin/{}-{}/{}-{}\".format(tok_type_src, tok_type_tgt, src_lang, tgt_lang)\n",
    "           \n",
    "            \n",
    "            # Create directories\n",
    "            print('create directories: ')\n",
    "            print('dir: ../data/{}'.format(FOLDER_NAME))\n",
    "            print('dir: ../data/{}'.format(FOLDER_NAME_BIN))\n",
    "\n",
    "            !mkdir -p ../data/{FOLDER_NAME}\n",
    "            !mkdir -p ../data/{FOLDER_NAME_BIN}\n",
    "\n",
    "            for split_name in ['train', 'valid', 'test']:\n",
    "                \n",
    "                write_spaced_tokens_to_file(dataset[split_name][src_lang][tok_type_src],\n",
    "                                            FOLDER_NAME, '{}.{}'.format(split_name, src_lang))\n",
    "                \n",
    "                write_spaced_tokens_to_file(dataset[split_name][tgt_lang][tok_type_tgt],\n",
    "                                            FOLDER_NAME, '{}.{}'.format(split_name, tgt_lang))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁bec ky , ▁um , ▁you ▁were ▁acting ▁particularly ▁strange ▁in ▁there ▁just ▁now .\n",
      "▁stay ▁with ▁her ▁so ▁anna ▁can ▁guide ▁you . ▁i ' m ▁going ▁back .\n",
      "▁look .\n",
      "▁oh , ▁no , ▁it ' s ▁the ▁other ▁way ▁around , ▁dr . ▁lewis .\n",
      "▁sort ▁of .\n",
      "▁bart ender , ▁something ▁really ▁strong , ▁please .\n",
      "▁yes , ▁obviously .\n",
      "▁la ' s ▁so ▁nice .\n",
      "▁i ' m ▁going ▁to ▁fix ▁it .\n",
      "▁i ▁get ▁b ored .\n"
     ]
    }
   ],
   "source": [
    "!head ../data/opensubtitles_tok/newmm-sentencepiece/th-en/train.en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "เบค กี้ เธอ ทำท่า แปลก ๆ เมื่อกี้ ใน ห้อง\n",
      "อยู่ กับ เธอ แอน นา จะ นำทาง คุณ ผม จะ กลับ ไป\n",
      "ฟัง นะ\n",
      "พอดี เลย ดร. ลี วิ ส\n",
      "แบบ ว่า\n",
      "เอ่อ บาร์ เท็น เด อร ์ ขอ อะไร ที่\n",
      "ก็ ใช่ ห น่ะ สิ\n",
      "แอลเอ สวย เนอะ\n",
      "ฉัน กำลังจะ แก้ ไขมัน\n",
      "ฉัน เบื่อ ละ\n"
     ]
    }
   ],
   "source": [
    "!head ../data/opensubtitles_tok/newmm-sentencepiece/th-en/train.th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
